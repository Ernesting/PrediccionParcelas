{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c37561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def algoritmo(df2, fecha, show, parcela):\n",
    "    diasTotales = 365 + 31\n",
    "    #from IPython.core.display import display, HTML\n",
    "    #display(HTML(\"<style>div.output_scroll { height: 90em; }</style>\"))\n",
    "\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import datetime\n",
    "\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    \n",
    "    borrarDebajo = 0.15\n",
    "    \n",
    "    fechas = list()\n",
    "    fechas2 = list()\n",
    "    valores = list()\n",
    "    valores2= list()\n",
    "    N = int(df2.size / 3) #numero de valores que tenemos para esta parcela\n",
    "\n",
    "    #Almacenamos los datos originales de la parcela en 'fechas' y 'valores'\n",
    "    #En 'fechas2' y 'valores2' almacenamos los datos cuyo ndvi esté por encima de 'borrarDebajo'\n",
    "    for i in range(N):\n",
    "        data = df2.iloc[i].fecha\n",
    "        data = str(data)\n",
    "        #Esto convierte la cadena YYYYMMDD en un tipo de dato fecha\n",
    "        dt = datetime.datetime.strptime(data, \"%Y%m%d\")\n",
    "        dtInt = int(dt.strftime(\"%j\"))\n",
    "        if int(data) >= 20220000:\n",
    "            dtInt = dtInt +365\n",
    "        #Convierto ese tipo de dato fecha en un entero, el dia del año de esa fecha\n",
    "        #Ej. 20210202 es el 2 de febrero y es el dia 33 del año\n",
    "        fechas.append(dtInt)\n",
    "        ndvi = df2.iloc[i].ndvi\n",
    "        valores.append(ndvi)\n",
    "        #Solo añado si el valor está por encima de la variable \"borrarDebajo\"\n",
    "        if ndvi >= borrarDebajo:\n",
    "            valores2.append(ndvi)\n",
    "            fechas2.append(dtInt)\n",
    "\n",
    "    #Borramos de 'valores2' y 'fechas2' los datos cuyos ndvi sean menores que el dato anterior y al siguiente (valores valle)\n",
    "    #Ejemplo: si tenemos los valores [3,1,2,4], borramos los valores 1 y 2\n",
    "    #Si tenemos los valores [3,1,4], borramos el valor 1\n",
    "    #Borramos los valores valle\n",
    "    for i in range(len(valores2)-1):\n",
    "        if i > 0 and i < len(valores2)-1:\n",
    "            #Si hay 2 valores juntos menores que el anterior y el siguiente, se borran ambos\n",
    "            if i < (len(valores2) - 2) and valores2[i-1] > valores2[i] and valores2[i-1] > valores2[i+1] and valores2[i+2] > valores2[i] and valores2[i+2] > valores2[i+1]:\n",
    "                del valores2[i]\n",
    "                del fechas2[i]\n",
    "                del valores2[i]\n",
    "                del fechas2[i]\n",
    "            #En el caso de que solo haya un minimo entre 2 puntos\n",
    "            elif valores2[i-1] > valores2[i] and valores2[i+1] > valores2[i]:\n",
    "                del valores2[i]\n",
    "                del fechas2[i]        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    #Variables:\n",
    "    saltoFechas = 10\n",
    "    saltoFechas2 = 20\n",
    "    saltoFechas3 = 30\n",
    "    añadirPorDebajo = 0.4 #antes se llamaba maximoMinimo\n",
    "    añadirPorEncima = 0.2\n",
    "\n",
    "    #Añado informacion al principio y final de año si no habia\n",
    "    if fechas2[0] > 0:\n",
    "        fechas2.insert(0, 0)\n",
    "        valores2.insert(0, valores2[0])\n",
    "    if fechas2[len(fechas2) -1] < diasTotales:\n",
    "        fechas2.insert(len(fechas2), diasTotales)\n",
    "        valores2.insert(len(valores2), valores2[len(valores2)-1])\n",
    "\n",
    "\n",
    "    #Si hay saltos muy grandes sin informacion se trata:\n",
    "    i = 0\n",
    "    while i < len(fechas2) - 1: \n",
    "        encontrado = False\n",
    "        #Si el salto es muy grande\n",
    "        if (fechas2[i+1]-fechas2[i]) >= saltoFechas3 and i+1 != (len(fechas2) -1) and i != 0:\n",
    "            #buscar maximos locales entre los dos puntos y\n",
    "            aux1 = 0\n",
    "            aux2 = 0\n",
    "            for j in range(len(fechas) - 1):\n",
    "                if fechas[j] <= fechas2[i] and fechas[j+1] >= fechas2[i]:\n",
    "                    aux1 = j\n",
    "                elif fechas[j] <= fechas2[i]  and fechas[j+1] >= fechas2[i]   :\n",
    "                    aux2 = j\n",
    "                    break\n",
    "            j = aux1 + 1\n",
    "            auxSum = 0\n",
    "            while (j < aux2):\n",
    "                if valores[j] > valores[j-1] and valores[j] > valores[j+1]:\n",
    "                    # y volverlos a añadir segun su valor\n",
    "                    if (valores2[i] <= 0.6 and valores2[i+1] <=0.6 and valores[j] <= añadirPorDebajo and valores[j] >= añadirPorEncima):\n",
    "                        fechas2.insert(i+1+ auxSum, fechas[j])\n",
    "                        valores2.insert(i+1+ auxSum, valores[j])\n",
    "                        auxSum = auxSum + 1\n",
    "                        encontrado = True\n",
    "                j = j + 1\n",
    "\n",
    "\n",
    "\n",
    "        if encontrado == False:    \n",
    "            #Si el salto es intermedio\n",
    "            if (fechas2[i+1]-fechas2[i]) >= saltoFechas2:\n",
    "                if valores2[i+1] > valores2[i]: #va hacia arriba\n",
    "                    fechas2.insert(i+1, fechas2[i] + ((fechas2[i+1] - fechas2[i]) / 3)*2)\n",
    "                    valores2.insert(i+1, valores2[i] + ((valores2[i+1] - valores2[i]) / 3))\n",
    "                else: #va hacia abajo\n",
    "                    fechas2.insert(i+1, fechas2[i] + ((fechas2[i+1] - fechas2[i]) / 3))\n",
    "                    valores2.insert(i+1,  valores2[i+1] + ((valores2[i] - valores2[i+1]) / 3))\n",
    "            #Si el salto es pequeño\n",
    "            elif (fechas2[i+1]-fechas2[i]) >= saltoFechas:\n",
    "                fechas2.insert(i+1, (fechas2[i+1]+fechas2[i])/2)\n",
    "                valores2.insert(i+1, (valores2[i+1]+valores2[i])/2)\n",
    "        i = i+1\n",
    "\n",
    "\n",
    "    #Plot    \n",
    "    from scipy.interpolate import make_interp_spline\n",
    "    from scipy.interpolate import interp1d\n",
    "\n",
    "    #Esto crea una linea de <diasTotales> puntos que pasa por todos los puntos que teniamos\n",
    "    X_Y_Spline = make_interp_spline(fechas2,valores2)        \n",
    "    X = np.linspace(0, diasTotales, diasTotales)\n",
    "    Y = X_Y_Spline(X)\n",
    "\n",
    "    dt = datetime.datetime.strptime(fecha, \"%Y%m%d\")\n",
    "    aux = int(dt.strftime(\"%j\"))\n",
    "    \n",
    "    if (show):\n",
    "        plt.figure(figsize=(17,5))\n",
    "        plt.title('parcela: '+ parcela)\n",
    "        plt.plot(fechas, valores,'r-')\n",
    "\n",
    "        plt.xticks(np.arange(0, diasTotales,10))\n",
    "\n",
    "        plt.plot(X, Y, 'b-')\n",
    "        plt.scatter(fechas, valores, c=valores, cmap='Set2')\n",
    "\n",
    "        #Dibujar las lineas verticales asociadas a las fechas de recepcion\n",
    "        #for recepcion in recepciones:\n",
    "        #    if recepcion[0] == parcela:\n",
    "        #        for aux in recepcion[1]:\n",
    "        #            dt = datetime.datetime.strptime(aux, \"%Y%m%d\")\n",
    "        #            aux2 = int(dt.strftime(\"%j\"))\n",
    "        #            plt.axvline(x=(aux2))  \n",
    "        #        break\n",
    "\n",
    "        #dt = datetime.datetime.strptime(fecha, \"%Y%m%d\")\n",
    "        #aux = int(dt.strftime(\"%j\"))\n",
    "        plt.axvline(x=(aux))  \n",
    "\n",
    "\n",
    "\n",
    "        plt.xlabel(\"X\")\n",
    "        plt.ylabel(\"Y\")\n",
    "        plt.ylim([0, 1])\n",
    "        plt.legend([\"puntos originales\",\"puntos modificados\"])\n",
    "        plt.show()\n",
    "        \n",
    "    return [Y, aux]\n",
    "\n",
    "def obtenerColumnas():\n",
    "    columnas = list()\n",
    "    columnas.append('parcela')\n",
    "    columnas.append('dia')\n",
    "    columnas.append('pendiente dia -15')\n",
    "    columnas.append('pendiente dia -10')\n",
    "    columnas.append('pendiente dia -5')\n",
    "    columnas.append('ndvi')\n",
    "    columnas.append('recogido')\n",
    "    \n",
    "    return columnas\n",
    "\n",
    "def inicializarDataframeIA(columnas):\n",
    "    import pandas as pd\n",
    "    df_ia = pd.DataFrame(columns=columnas())\n",
    "    \n",
    "    return df_ia\n",
    "\n",
    "def obtenerParcelasConUnaRecepcion(PARCELASMAIZ20212022CONFECHAS):\n",
    "    import pandas as pd\n",
    "\n",
    "    dfFechas = pd.read_csv(PARCELASMAIZ20212022CONFECHAS)\n",
    "    \n",
    "    freq = dfFechas['PAC'].value_counts()\n",
    "    items = freq[freq==1].index\n",
    "    only_1_reception = dfFechas[dfFechas['PAC'].isin(items)]\n",
    "\n",
    "    newPac = only_1_reception[\"PAC\"].str.replace(\":\", \"_\")\n",
    "    newDate = only_1_reception[\"Fecha de carga\"].str.replace(\"-\", \"\")\n",
    "\n",
    "    only_1_reception[\"PAC\"] = newPac\n",
    "    only_1_reception[\"Fecha de carga\"] = newDate\n",
    "    only_1_reception['Fecha de carga'] = only_1_reception['Fecha de carga'].apply(str)\n",
    "    \n",
    "    return only_1_reception\n",
    "\n",
    "def añadirADataframe(parcela, diaDeCarga, valoresDias, columnas, df,diasPendiente, diasMargen):\n",
    "    import pandas as pd\n",
    "    for i in range(len(valoresDias)):\n",
    "        if ((i - (diasPendiente[0])) >= 0 and (i+1) - diaDeCarga > -15 and (i+1) - diaDeCarga <= 5  ):\n",
    "            \n",
    "            lista = list()\n",
    "            lista.append(parcela)\n",
    "            lista.append(i + 1)\n",
    "            for j in diasPendiente:\n",
    "                lista.append((valoresDias[i - j] - valoresDias[i])/j)\n",
    "                \n",
    "            lista.append(valoresDias[i])\n",
    "            if ((diaDeCarga - (i + 1)) <= diasMargen and (diaDeCarga - (i + 1)) >= 0):\n",
    "                lista.append(1)\n",
    "            else:\n",
    "                lista.append(0)\n",
    "\n",
    "            dfAux = pd.DataFrame([lista], columns=columnas(), index=[len(df)])\n",
    "            df = df.append(dfAux)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def obtenerDatosEntrenables(datosNoEntrenables2122, PARCELASMAIZ20212022CONFECHAS):\n",
    "    import pandas as pd\n",
    "    dfFechas = obtenerParcelasConUnaRecepcion(PARCELASMAIZ20212022CONFECHAS)\n",
    "    \n",
    "    \n",
    "    dfDatos = pd.read_csv(datosNoEntrenables2122)\n",
    "    dfDatos = dfDatos.sort_values(by=[\"fecha\",\"parcela\"], ascending=True)\n",
    "    \n",
    "    parcelasQueTengo = dfDatos[\"parcela\"].unique()\n",
    "    parcelasConUnaRecepcion = dfFechas[\"PAC\"].unique()\n",
    "\n",
    "    df_ndvi_of_only_1_reception = dfDatos[dfDatos.parcela.isin(dfFechas[\"PAC\"].unique())]\n",
    "    parcelas = df_ndvi_of_only_1_reception['parcela'].unique()\n",
    "    \n",
    "    \n",
    "    df = inicializarDataframeIA(obtenerColumnas)\n",
    "    i = 0\n",
    "    j = len(parcelas)\n",
    "    diaPrimeraRecepcion = [15,10,5]\n",
    "    diaMargen = 4\n",
    "    \n",
    "    \n",
    "    for parcela in parcelas:\n",
    "\n",
    "        df2 = df_ndvi_of_only_1_reception.loc[df_ndvi_of_only_1_reception['parcela'] == parcela]\n",
    "        df2 = df2.drop_duplicates()\n",
    "        if (not df2.empty):\n",
    "            fecha_df = dfFechas.loc[dfFechas[\"PAC\"] == parcela] \n",
    "            fecha = fecha_df.iloc[0][\"Fecha de carga\"]\n",
    "            X, dia_recepcion = algoritmo(df2, fecha, True, parcela)\n",
    "            if (dia_recepcion > diaPrimeraRecepcion[0]):\n",
    "                df = añadirADataframe(parcela, dia_recepcion, X, obtenerColumnas, df, diaPrimeraRecepcion, diaMargen)\n",
    "            i = i + 1\n",
    "            print(str(i) + \"/\" + str(j)) \n",
    "        else:\n",
    "            j = j - 1\n",
    "        \n",
    "\n",
    "    return df\n",
    "\n",
    "def separarTrainTest(dataframe):\n",
    "    parcelas = dataframe['parcela'].unique()\n",
    "    N = len(parcelas)\n",
    "\n",
    "    #si hay 2 recintos de la misma zona uno lo meto a test\n",
    "    test= list()\n",
    "    train = list(parcelas)\n",
    "    contador = 1\n",
    "    for i in range(N):\n",
    "        parcelaAnterior = parcelas[i - 1].split('_')\n",
    "        aux = ''\n",
    "        for j in range(5):\n",
    "            aux = aux + parcelaAnterior[j] + '_'\n",
    "\n",
    "\n",
    "        if parcelas[i].startswith(aux):\n",
    "            test.append(parcelas[i])\n",
    "            train.remove(parcelas[i])\n",
    "            if len(test) >= N * 0.1:\n",
    "                break\n",
    "\n",
    "    dataframeTrain = dataframe[dataframe['parcela'].isin(train)]\n",
    "    dataframeTest =  dataframe[dataframe['parcela'].isin(test)]\n",
    "    \n",
    "    return [dataframeTrain, dataframeTest]\n",
    "\n",
    "def obtenerModelo(dataframeTrain, regularizacion=1):\n",
    "    # Perceptron de un solo nivel\n",
    "    from keras.layers import Dense\n",
    "    from keras.regularizers import l2\n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    \n",
    "    X = np.asarray(dataframeTrain.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    \n",
    "    normalizer = layers.Normalization()\n",
    "    normalizer.adapt(X)\n",
    "    \n",
    "    n = dataframeTrain.drop(columns=['parcela','dia','recogido']).shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(normalizer)\n",
    "    #,kernel_initializer=initializer\n",
    "    #model.add(Dense(n**3, activation='relu', input_shape=(n,), kernel_regularizer=l2(regularizacion)))\n",
    "    #añadir capa\n",
    "    model.add(Dense(n**2, activation='relu', input_shape=(n,), kernel_regularizer=l2(regularizacion)))\n",
    "    model.add(Dense(n, activation='relu', kernel_regularizer=l2(regularizacion)))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(regularizacion)))\n",
    "    #\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(),  metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', threshold=0.6), keras.metrics.Recall(name='recall', threshold = 0.6)])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def obtenerModelo3(dataframeTrain, regularizacion=1):\n",
    "    # Perceptron de un solo nivel\n",
    "    from keras.layers import Dense\n",
    "    from keras.regularizers import l2\n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    \n",
    "    X = np.asarray(dataframeTrain.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    \n",
    "    normalizer = layers.Normalization()\n",
    "    normalizer.adapt(X)\n",
    "    \n",
    "    n = dataframeTrain.drop(columns=['parcela','dia','recogido']).shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(normalizer)\n",
    "    #,kernel_initializer=initializer\n",
    "    #model.add(Dense(n**3, activation='relu', input_shape=(n,), kernel_regularizer=l2(regularizacion)))\n",
    "    #añadir capa\n",
    "    #model.add(Dense(n**2, activation='relu', input_shape=(n,), kernel_regularizer=l2(regularizacion)))\n",
    "    model.add(Dense(n, activation='relu',input_shape=(n,), kernel_regularizer=l2(regularizacion)))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(regularizacion)))\n",
    "    #\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(),  metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', threshold=0.6), keras.metrics.Recall(name='recall')])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def obtenerModelo4(dataframeTrain, regularizacion=1):\n",
    "    # Perceptron de un solo nivel\n",
    "    from keras.layers import Dense\n",
    "    from keras.regularizers import l2\n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    \n",
    "    X = np.asarray(dataframeTrain.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    \n",
    "    normalizer = layers.Normalization()\n",
    "    normalizer.adapt(X)\n",
    "    \n",
    "    n = dataframeTrain.drop(columns=['parcela','dia','recogido']).shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(normalizer)\n",
    "    #,kernel_initializer=initializer\n",
    "    model.add(Dense(n**3, activation='relu', input_shape=(n,), kernel_regularizer=l2(regularizacion)))\n",
    "    #añadir capa\n",
    "    model.add(Dense(n**2, activation='relu',  kernel_regularizer=l2(regularizacion)))\n",
    "    model.add(Dense(n, activation='relu', kernel_regularizer=l2(regularizacion)))\n",
    "    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(regularizacion)))\n",
    "    #\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(),  metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', threshold=0.6), keras.metrics.Recall(name='recall', threshold = 0.6)])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def obtenerModelo5(dataframeTrain, regularizacion=1):\n",
    "    # Perceptron de un solo nivel\n",
    "    from keras.layers import Dense\n",
    "    from keras.regularizers import l2\n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    from tensorflow.keras.layers import Dropout\n",
    "    from tensorflow.keras.constraints import MaxNorm\n",
    "    from tensorflow.keras.optimizers import SGD\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    \n",
    "    X = np.asarray(dataframeTrain.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    \n",
    "    normalizer = layers.Normalization()\n",
    "    normalizer.adapt(X)\n",
    "    \n",
    "    n = dataframeTrain.drop(columns=['parcela','dia','recogido']).shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(normalizer)\n",
    "    #,kernel_initializer=initializer\n",
    "    # Compile model\n",
    "    #añadir capa\n",
    "    model.add(Dense(n, activation='relu', input_shape=(n,), kernel_constraint=MaxNorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='relu', kernel_constraint=MaxNorm(3)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    #\n",
    "    sgd = SGD(learning_rate=0.1, momentum=0.9)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=sgd,  metrics=[tf.keras.metrics.BinaryAccuracy(name='binary_accuracy', threshold=0.6), keras.metrics.Recall(name='recall')])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def obtenerModelo2(dataframeTrain):\n",
    "    # Perceptron de un solo nivel\n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "\n",
    "    X = np.asarray(dataframeTrain.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    normalizer = layers.Normalization()\n",
    "    normalizer.adapt(X) \n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    #model.add(normalizer)\n",
    "    \n",
    "    model.add(Dense(4096, kernel_initializer='normal',input_dim = dataframeTrain.drop(columns=['parcela','dia','recogido']).shape[1], activation='sigmoid'))\n",
    "\n",
    "    # The Hidden Layers :\n",
    "    model.add(Dense(2048 ,activation='softmax'))\n",
    "    model.add(Dense(1024 ,activation='sigmoid'))\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dense(256,activation='softmax'))\n",
    "    model.add(Dense(128,activation='sigmoid'))\n",
    "    model.add(Dense(64,activation='relu'))\n",
    "    model.add(Dense(32,activation='softmax'))\n",
    "    model.add(Dense(16,activation='sigmoid'))\n",
    "    model.add(Dense(8,activation='relu'))\n",
    "    model.add(Dense(4,activation='softmax'))\n",
    "    \n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    #\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=Adam(),  metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def plot_history(history):\n",
    "    loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' not in s]\n",
    "    val_loss_list = [s for s in history.history.keys() if 'loss' in s and 'val' in s]\n",
    "    acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' not in s]\n",
    "    val_acc_list = [s for s in history.history.keys() if 'acc' in s and 'val' in s]\n",
    "    \n",
    "    if len(loss_list) == 0:\n",
    "        print('Loss is missing in history')\n",
    "        return \n",
    "    \n",
    "    ## As loss always exists\n",
    "    epochs = range(1,len(history.history[loss_list[0]]) + 1)\n",
    "    \n",
    "    ## Loss\n",
    "    fig, axs = plt.subplots(1, 2,  figsize=(12, 6))\n",
    "    for l in loss_list:\n",
    "        axs[0].plot(epochs, history.history[l], 'b', label='Training loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    for l in val_loss_list:\n",
    "        axs[0].plot(epochs, history.history[l], 'g', label='Validation loss (' + str(str(format(history.history[l][-1],'.5f'))+')'))\n",
    "    \n",
    "    axs[0].set(title='Loss', xlabel='Epochs', ylabel='Loss')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "    \n",
    "    ## Accuracy\n",
    "    for l in acc_list:\n",
    "        axs[1].plot(epochs, history.history[l], 'b', label='Training accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "    for l in val_acc_list:    \n",
    "        axs[1].plot(epochs, history.history[l], 'g', label='Validation accuracy (' + str(format(history.history[l][-1],'.5f'))+')')\n",
    "\n",
    "    axs[1].set(title='Accuracy', xlabel='Epochs', ylabel='Accuracy')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend()\n",
    "    plt.show()\n",
    "    \n",
    "def anyadirUnos(df):\n",
    "    df['unos'] = [1]*len(df)\n",
    "    \n",
    "def RecepcionToBool(recogido):\n",
    "    aux = np.zeros(2)\n",
    "    aux[recogido] = 1\n",
    "    return aux\n",
    "            \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    #plt.tight_layout()\n",
    "\n",
    "def plot_mnist_confusion_matrix(y_test, y_pred, normalize=False):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    \n",
    "    import keras\n",
    "    from keras.datasets import mnist\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from tensorflow.keras.optimizers import RMSprop, Adam, SGD\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    umbral = 0.01\n",
    "    \n",
    "    y_tst = np.zeros(len(y_test))\n",
    "    for i in range(len(y_test) - 1):\n",
    "        #if y_test[i][1] >= umbral:\n",
    "        #    y_tst[i] = 1\n",
    "        y_tst[i] = np.argmax(y_test[i])\n",
    "    #y_tst = [np.argmax(y) for y in y_test]\n",
    "    \n",
    "    y_prd = np.zeros(len(y_pred))\n",
    "    for i in range(len(y_pred) - 1):\n",
    "        #if y_pred[i][1] >= umbral:\n",
    "        #    y_prd[i] = 1\n",
    "        y_prd[i] = np.argmax(y_pred[i])\n",
    "    #y_prd = [np.argmax(y) for y in y_pred]\n",
    "\n",
    "    cnf_matrix = confusion_matrix(y_tst, y_prd)\n",
    "    \n",
    "    yprueba = list()\n",
    "    for y in y_tst:\n",
    "        yprueba.append(y)\n",
    "    for y in y_prd:\n",
    "        yprueba.append(y)\n",
    "    class_names=np.unique(yprueba)\n",
    "    print(class_names)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                          normalize=normalize)\n",
    "    \n",
    "def quitarDatosMalos(df):\n",
    "    #QUITA LAS PARCELAS QUE NO TENGAN 20 DIAS DE DATOS\n",
    "    parcelasAQuitar = list()\n",
    "    parcelas = df['parcela'].unique()\n",
    "    for parcela in parcelas:\n",
    "        if len(df.loc[df['parcela'] == parcela]) != 20:\n",
    "            parcelasAQuitar.append(parcela)\n",
    "    \n",
    "    df = df[~df['parcela'].isin(parcelasAQuitar)]\n",
    "    return df\n",
    "    \n",
    "def anyadirRelacionesParametros2(df):\n",
    "    columnas = df.shape[1]\n",
    "    for i in range(columnas):\n",
    "        for j in range(columnas):\n",
    "            if i < j:\n",
    "                nombreColumna = 'col ' + str(i+1) + ' * col ' + str(j+1)\n",
    "                df[nombreColumna] = df.iloc[:,i] * df.iloc[:,j]\n",
    "                \n",
    "    return df\n",
    "    \n",
    "def anyadirRelacionesParametros(df, listaColumnas = ['parcela','dia','recogido','ndvi']):\n",
    "    aux = pd.DataFrame()\n",
    "    for i in listaColumnas:\n",
    "        aux[i] = df[i]\n",
    "        df = df.drop(columns=[i])\n",
    "        \n",
    "    df = anyadirRelacionesParametros2(df)\n",
    "    for i in listaColumnas:\n",
    "        df[i] = aux[i]\n",
    "    return df\n",
    "    \n",
    "def entrenarModelo(model, dataframeTrain, dataframeTest, batch_size, epochs, callbacks_list):\n",
    "    def RecepcionToBool(recogido):\n",
    "        aux = np.zeros(2)\n",
    "        aux[recogido] = 1\n",
    "        return aux\n",
    "\n",
    "    #DATA TRAINING   \n",
    "    import time\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras import layers\n",
    "    N = len(dataframeTrain)\n",
    "\n",
    "\n",
    "    verbose = True\n",
    "    t0 = time.perf_counter()\n",
    "    X = np.asarray(dataframeTrain.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    y = np.asarray(dataframeTrain[[\"recogido\"]]).astype(np.float32)\n",
    "    \n",
    "    #DATA TESTING\n",
    "    N = len(dataframeTest)\n",
    "\n",
    "    Xtest = np.asarray(dataframeTest.drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "    ytest = np.asarray(dataframeTest[[\"recogido\"]]).astype(np.float32)\n",
    "    \n",
    "\n",
    "\n",
    "    history = model.fit(X, y,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=False, \n",
    "                        callbacks=callbacks_list,\n",
    "                       validation_data=(Xtest,ytest))\n",
    "\n",
    "    #model.predict(X_cv)\n",
    "\n",
    "    train_time = time.perf_counter() - t0\n",
    "    print('%s %.3f%s' %  ('Training time: ', train_time, 's') )\n",
    "    plot_history(history)\n",
    "    \n",
    "def predecirYMostrarMatrizConfusion(df,model,pesos, umbral = 0.6):\n",
    "    df = df.reset_index()\n",
    "    df = df.drop(columns=['index'])\n",
    "    X = df.drop(columns=['parcela','dia','recogido'])\n",
    "    y = df['recogido']\n",
    "    \n",
    "    model.load_weights(pesos)\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_pred = model.predict(X, verbose=True)\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] >= umbral and y[i] == 1:\n",
    "            tp = tp + 1\n",
    "        elif y_pred[i] >= umbral and y[i] == 0:\n",
    "            fp = fp + 1\n",
    "        elif y_pred[i] < umbral and y[i] == 1:\n",
    "            fn = fn + 1\n",
    "        else:\n",
    "            tn = tn + 1\n",
    "\n",
    "\n",
    "    test_score = (tp + tn)/ len(X)\n",
    "    print('%s %2.2f%s' % ('Accuracy test:  ', 100*test_score, '%'))\n",
    "\n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    ind = np.asarray([0.0,1.0]).astype(np.float32)\n",
    "    mat = np.asarray([[tn, fp], [fn, tp]]).astype(np.int32)\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plot_confusion_matrix(mat, classes=ind,\n",
    "                              normalize=False)\n",
    "\n",
    "\n",
    "\n",
    "# Define la función de poda\n",
    "def prune_low_weights(model, pruning_threshold):\n",
    "    from keras import backend as K\n",
    "    for layer in model.layers:\n",
    "        if hasattr(layer, 'kernel_regularizer'):\n",
    "            weights = layer.get_weights()[0]  # Obtiene los pesos de la capa\n",
    "            mask = K.abs(weights) > pruning_threshold  # Aplica el umbral\n",
    "            weights *= mask  # Poda los pesos por debajo del umbral\n",
    "            layer.set_weights([weights])  # Establece los pesos podados en la capa\n",
    "            \n",
    "def parcelasConAciertos(dataframe,model,  umbral = 0.6):\n",
    "    dataframeRecogidoUno = dataframe.loc[dataframe['recogido'] == 1]\n",
    "    parcelasAObservar = dataframe['parcela'].unique()\n",
    "    print(\"hay \", str(len(parcelasAObservar)), \" parcelas a observar\")\n",
    "    print('------------------')\n",
    "    cantidad = 0\n",
    "    for parcela in parcelasAObservar:\n",
    "        unoAcertado = False\n",
    "        datos = dataframe.loc[dataframe['parcela'] == parcela]\n",
    "        dias = dataframeRecogidoUno.loc[dataframeRecogidoUno['parcela'] == parcela]['dia']\n",
    "        print(parcela, 'dias que deberia dar 1 la prediccion:')\n",
    "        print(dias)\n",
    "        Xtest = np.asarray(dataframe.loc[dataframe['parcela'] == parcela].drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "        ytest = np.asarray(dataframe.loc[dataframe['parcela'] == parcela][[\"recogido\"]]).astype(np.float32)\n",
    "        ypred = model.predict(Xtest, verbose=0)\n",
    "        print(\"dias que ha dado 1 la prediccion: \")\n",
    "        for i in range(len(ypred)):\n",
    "            if ypred[i] >= umbral:\n",
    "                print('dia: ', datos.iloc[i]['dia'])\n",
    "                if ytest[i] == 1 and unoAcertado == False:\n",
    "                    cantidad = cantidad + 1\n",
    "                    unoAcertado = True\n",
    "                    \n",
    "        if (unoAcertado == True):\n",
    "            print(\"ha acertado por lo menos un 1 de los que deberia\")\n",
    "\n",
    "        print('------------------')\n",
    "\n",
    "    print('Parcelas con acierto: ',cantidad, \"de\", str(len(parcelasAObservar)))\n",
    "    return parcelasAObservar\n",
    "    \n",
    "def obtenerMejorModelo():\n",
    "    import os\n",
    "    import ipynbname\n",
    "    directory = ipynbname.name()\n",
    "    baccuracyMax = 0\n",
    "    baccuracyMaxFile = ''\n",
    "    val_baccuracyMax = 0\n",
    "    val_baccuracyMaxFile = ''\n",
    "    recallMax = 0\n",
    "    recallMaxFile = ''\n",
    "    val_recallMax = 0\n",
    "    val_recallMaxFile = ''\n",
    "    # iterate over files in\n",
    "    # that directory\n",
    "    for subdirectory in os.listdir(directory):\n",
    "        f = os.path.join(directory, subdirectory)\n",
    "        # checking if it is a file\n",
    "        for filename in os.listdir(f):\n",
    "            campos = filename.split('-')\n",
    "            f1 = os.path.join(f, filename)\n",
    "            if (len(campos)) == 5:\n",
    "                if (campos[3] == 'binary_accuracy' and float(campos[4][:len(campos[4])-5]) > float(baccuracyMax)):\n",
    "                    baccuracyMax = float(campos[4][:len(campos[4])-5])\n",
    "                    baccuracyMaxFile = f1\n",
    "                if (campos[3] == 'val_binary_accuracy' and float(campos[4][:len(campos[4])-5]) > float(val_baccuracyMax)):\n",
    "                    val_baccuracyMax = float(campos[4][:len(campos[4])-5])\n",
    "                    val_baccuracyMaxFile = f1\n",
    "                if (campos[3] == 'recall' and float(campos[4][:len(campos[4])-5]) > float(recallMax)):\n",
    "                    recallMax = float(campos[4][:len(campos[4])-5])\n",
    "                    recallMaxFile = f1\n",
    "                if (campos[3] == 'val_recall' and float(campos[4][:len(campos[4])-5]) > float(val_recallMax)):\n",
    "                    val_recallMax = float(campos[4][:len(campos[4])-5])\n",
    "                    val_recallMaxFile = f1\n",
    "\n",
    "    print(\"Mejor binary_accuracy: \", baccuracyMax)\n",
    "    print(baccuracyMaxFile)\n",
    "    print(\"Mejor val_binary_accuracy: \", val_baccuracyMax)\n",
    "    print(val_baccuracyMaxFile)\n",
    "    print(\"Mejor recall: \", recallMax)\n",
    "    print(recallMaxFile)\n",
    "    print(\"Mejor val_recall: \", val_recallMax)\n",
    "    print(val_recallMaxFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae55674",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrarParcelasSinAciertos():\n",
    "\n",
    "    def algoritmo(df2, fecha, show, tp, fp):\n",
    "\n",
    "        #from IPython.core.display import display, HTML\n",
    "        #display(HTML(\"<style>div.output_scroll { height: 90em; }</style>\"))\n",
    "\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        import datetime\n",
    "\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        borrarDebajo = 0.15\n",
    "\n",
    "        fechas = list()\n",
    "        fechas2 = list()\n",
    "        valores = list()\n",
    "        valores2= list()\n",
    "        N = int(df2.size / 3) #numero de valores que tenemos para esta parcela\n",
    "\n",
    "        #Almacenamos los datos originales de la parcela en 'fechas' y 'valores'\n",
    "        #En 'fechas2' y 'valores2' almacenamos los datos cuyo ndvi esté por encima de 'borrarDebajo'\n",
    "        for i in range(N):\n",
    "            data = df2.iloc[i].fecha\n",
    "            data = str(data)\n",
    "            #Esto convierte la cadena YYYYMMDD en un tipo de dato fecha\n",
    "            dt = datetime.datetime.strptime(data, \"%Y%m%d\")\n",
    "            #Convierto ese tipo de dato fecha en un entero, el dia del año de esa fecha\n",
    "            #Ej. 20210202 es el 2 de febrero y es el dia 33 del año\n",
    "            fechas.append(int(dt.strftime(\"%j\")))\n",
    "            ndvi = df2.iloc[i].ndvi\n",
    "            valores.append(ndvi)\n",
    "            #Solo añado si el valor está por encima de la variable \"borrarDebajo\"\n",
    "            if ndvi >= borrarDebajo:\n",
    "                valores2.append(ndvi)\n",
    "                fechas2.append(int(dt.strftime(\"%j\")))\n",
    "\n",
    "        #Borramos de 'valores2' y 'fechas2' los datos cuyos ndvi sean menores que el dato anterior y al siguiente (valores valle)\n",
    "        #Ejemplo: si tenemos los valores [3,1,2,4], borramos los valores 1 y 2\n",
    "        #Si tenemos los valores [3,1,4], borramos el valor 1\n",
    "        #Borramos los valores valle\n",
    "        for i in range(len(valores2)-1):\n",
    "            if i > 0 and i < len(valores2)-1:\n",
    "                #Si hay 2 valores juntos menores que el anterior y el siguiente, se borran ambos\n",
    "                if i < (len(valores2) - 2) and valores2[i-1] > valores2[i] and valores2[i-1] > valores2[i+1] and valores2[i+2] > valores2[i] and valores2[i+2] > valores2[i+1]:\n",
    "                    del valores2[i]\n",
    "                    del fechas2[i]\n",
    "                    del valores2[i]\n",
    "                    del fechas2[i]\n",
    "                #En el caso de que solo haya un minimo entre 2 puntos\n",
    "                elif valores2[i-1] > valores2[i] and valores2[i+1] > valores2[i]:\n",
    "                    del valores2[i]\n",
    "                    del fechas2[i]        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Variables:\n",
    "        saltoFechas = 10\n",
    "        saltoFechas2 = 20\n",
    "        saltoFechas3 = 30\n",
    "        añadirPorDebajo = 0.4 #antes se llamaba maximoMinimo\n",
    "        añadirPorEncima = 0.2\n",
    "\n",
    "        #Añado informacion al principio y final de año si no habia\n",
    "        if fechas2[0] > 0:\n",
    "            fechas2.insert(0, 0)\n",
    "            valores2.insert(0, valores2[0])\n",
    "        if fechas2[len(fechas2) -1] < 365:\n",
    "            fechas2.insert(len(fechas2), 365)\n",
    "            valores2.insert(len(valores2), valores2[len(valores2)-1])\n",
    "\n",
    "\n",
    "        #Si hay saltos muy grandes sin informacion se trata:\n",
    "        i = 0\n",
    "        while i < len(fechas2) - 1: \n",
    "            encontrado = False\n",
    "            #Si el salto es muy grande\n",
    "            if (fechas2[i+1]-fechas2[i]) >= saltoFechas3 and i+1 != (len(fechas2) -1) and i != 0:\n",
    "                #buscar maximos locales entre los dos puntos y\n",
    "                aux1 = 0\n",
    "                aux2 = 0\n",
    "                for j in range(len(fechas) - 1):\n",
    "                    if fechas[j] <= fechas2[i] and fechas[j+1] >= fechas2[i]:\n",
    "                        aux1 = j\n",
    "                    elif fechas[j] <= fechas2[i]  and fechas[j+1] >= fechas2[i]   :\n",
    "                        aux2 = j\n",
    "                        break\n",
    "                j = aux1 + 1\n",
    "                auxSum = 0\n",
    "                while (j < aux2):\n",
    "                    if valores[j] > valores[j-1] and valores[j] > valores[j+1]:\n",
    "                        # y volverlos a añadir segun su valor\n",
    "                        if (valores2[i] <= 0.6 and valores2[i+1] <=0.6 and valores[j] <= añadirPorDebajo and valores[j] >= añadirPorEncima):\n",
    "                            fechas2.insert(i+1+ auxSum, fechas[j])\n",
    "                            valores2.insert(i+1+ auxSum, valores[j])\n",
    "                            auxSum = auxSum + 1\n",
    "                            encontrado = True\n",
    "                    j = j + 1\n",
    "\n",
    "\n",
    "\n",
    "            if encontrado == False:    \n",
    "                #Si el salto es intermedio\n",
    "                if (fechas2[i+1]-fechas2[i]) >= saltoFechas2:\n",
    "                    if valores2[i+1] > valores2[i]: #va hacia arriba\n",
    "                        fechas2.insert(i+1, fechas2[i] + ((fechas2[i+1] - fechas2[i]) / 3)*2)\n",
    "                        valores2.insert(i+1, valores2[i] + ((valores2[i+1] - valores2[i]) / 3))\n",
    "                    else: #va hacia abajo\n",
    "                        fechas2.insert(i+1, fechas2[i] + ((fechas2[i+1] - fechas2[i]) / 3))\n",
    "                        valores2.insert(i+1,  valores2[i+1] + ((valores2[i] - valores2[i+1]) / 3))\n",
    "                #Si el salto es pequeño\n",
    "                elif (fechas2[i+1]-fechas2[i]) >= saltoFechas:\n",
    "                    fechas2.insert(i+1, (fechas2[i+1]+fechas2[i])/2)\n",
    "                    valores2.insert(i+1, (valores2[i+1]+valores2[i])/2)\n",
    "            i = i+1\n",
    "\n",
    "\n",
    "        #Plot    \n",
    "        from scipy.interpolate import make_interp_spline\n",
    "        from scipy.interpolate import interp1d\n",
    "\n",
    "        #Esto crea una linea de 365 puntos que pasa por todos los puntos que teniamos\n",
    "        X_Y_Spline = make_interp_spline(fechas2,valores2)        \n",
    "        X = np.linspace(0, 365, 365)\n",
    "        Y = X_Y_Spline(X)\n",
    "\n",
    "        dt = datetime.datetime.strptime(fecha, \"%Y%m%d\")\n",
    "        aux = int(dt.strftime(\"%j\"))\n",
    "\n",
    "        if (show):\n",
    "            plt.figure(figsize=(17,5))\n",
    "            plt.title('parcela: '+ parcela)\n",
    "            plt.plot(fechas, valores,'r-')\n",
    "\n",
    "            plt.xticks(np.arange(0, 365,10))\n",
    "\n",
    "            plt.plot(X, Y, 'b-')\n",
    "            plt.scatter(fechas, valores, c=valores, cmap='Set2')\n",
    "\n",
    "            #Dibujar las lineas verticales asociadas a las fechas de recepcion\n",
    "            #for recepcion in recepciones:\n",
    "            #    if recepcion[0] == parcela:\n",
    "            #        for aux in recepcion[1]:\n",
    "            #            dt = datetime.datetime.strptime(aux, \"%Y%m%d\")\n",
    "            #            aux2 = int(dt.strftime(\"%j\"))\n",
    "            #            plt.axvline(x=(aux2))  \n",
    "            #        break\n",
    "\n",
    "            #dt = datetime.datetime.strptime(fecha, \"%Y%m%d\")\n",
    "            #aux = int(dt.strftime(\"%j\"))\n",
    "            plt.axvline(x=(aux), linewidth=2, color='black') \n",
    "            [plt.axvline(_x, linewidth=1, color='r') for _x in fp]\n",
    "            [plt.axvline(_x, linewidth=1, color='g') for _x in tp]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plt.xlabel(\"X\")\n",
    "            plt.ylabel(\"Y\")\n",
    "            plt.ylim([0, 1])\n",
    "            plt.legend([\"puntos originales\",\"puntos modificados\",\"recepcion\", \"falsos positivo\"])\n",
    "            plt.show()\n",
    "\n",
    "        return [Y, aux]\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    dfFechas = pd.read_csv('PARCELAS-MAIZ-2021-2022-CON-FECHAS.csv')\n",
    "\n",
    "    freq = dfFechas['PAC'].value_counts()\n",
    "    items = freq[freq==1].index\n",
    "    only_1_reception = dfFechas[dfFechas['PAC'].isin(items)]\n",
    "\n",
    "    newPac = only_1_reception[\"PAC\"].str.replace(\":\", \"_\")\n",
    "    newDate = only_1_reception[\"Fecha de carga\"].str.replace(\"-\", \"\")\n",
    "\n",
    "    only_1_reception[\"PAC\"] = newPac\n",
    "    only_1_reception[\"Fecha de carga\"] = newDate\n",
    "    only_1_reception['Fecha de carga'] = only_1_reception['Fecha de carga'].apply(str)\n",
    "\n",
    "    df = pd.read_csv('TODOSLOSRECINTOS.csv')\n",
    "\n",
    "    #Ordeno por fecha y parcela\n",
    "    sorted_df = df.sort_values(by=[\"fecha\",\"parcela\"], ascending=True)\n",
    "    sorted_df = sorted_df.drop(columns=['Unnamed: 0'])\n",
    "    parcelasQueTengo = sorted_df[\"parcela\"].unique()\n",
    "    parcelasConUnaRecepcion = only_1_reception[\"PAC\"].unique()\n",
    "\n",
    "    df_ndvi_of_only_1_reception = sorted_df[sorted_df.parcela.isin(only_1_reception[\"PAC\"].unique())]\n",
    "\n",
    "    dias1 = 7\n",
    "    dias2 = 180\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    #parcelas = df_ndvi_of_only_1_reception['parcela'].unique()\n",
    "    parcelas = parcelasAObservar\n",
    "    for parcela in parcelas:\n",
    "        df2 = df_ndvi_of_only_1_reception.loc[df_ndvi_of_only_1_reception['parcela'] == parcela]\n",
    "        df2 = df2.drop_duplicates()\n",
    "        if (not df2.empty):\n",
    "            fecha_df = only_1_reception.loc[only_1_reception[\"PAC\"] == parcela] \n",
    "            fecha = fecha_df.iloc[0][\"Fecha de carga\"]\n",
    "\n",
    "            datos = dataframeAux.loc[dataframeAux['parcela'] == parcela]\n",
    "            dias = dataframeDias.loc[dataframeDias['parcela'] == parcela]['dia']\n",
    "            #print('------------------')\n",
    "            #print(parcela, 'dias:')\n",
    "            tp = list(dias)\n",
    "            #print(dias)\n",
    "            Xtest = np.asarray(dataframeAux.loc[dataframeAux['parcela'] == parcela].drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "            ytest = np.asarray(dataframeAux.loc[dataframeAux['parcela'] == parcela][[\"recogido\"]]).astype(np.float32)\n",
    "            ypred = model.predict(Xtest, verbose=0)\n",
    "            fp = list()\n",
    "            for i in range(len(ypred)):\n",
    "                if ypred[i] >= 0.6:\n",
    "                    fp.append(datos.iloc[i]['dia'])\n",
    "\n",
    "\n",
    "            X, dia_recepcion = algoritmo(df2, fecha, True, tp, fp)\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def mostrarParcelasConAciertos():\n",
    "    def intersection(lst1, lst2):\n",
    "                lst3 = [value for value in lst1 if value in lst2]\n",
    "                return lst3\n",
    "    def algoritmo(df2, fecha, show, tp, fp):\n",
    "\n",
    "        #from IPython.core.display import display, HTML\n",
    "        #display(HTML(\"<style>div.output_scroll { height: 90em; }</style>\"))\n",
    "\n",
    "        import pandas as pd\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        import datetime\n",
    "\n",
    "        import warnings\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "        borrarDebajo = 0.15\n",
    "\n",
    "        fechas = list()\n",
    "        fechas2 = list()\n",
    "        valores = list()\n",
    "        valores2= list()\n",
    "        N = int(df2.size / 3) #numero de valores que tenemos para esta parcela\n",
    "\n",
    "        #Almacenamos los datos originales de la parcela en 'fechas' y 'valores'\n",
    "        #En 'fechas2' y 'valores2' almacenamos los datos cuyo ndvi esté por encima de 'borrarDebajo'\n",
    "        for i in range(N):\n",
    "            data = df2.iloc[i].fecha\n",
    "            data = str(data)\n",
    "            #Esto convierte la cadena YYYYMMDD en un tipo de dato fecha\n",
    "            dt = datetime.datetime.strptime(data, \"%Y%m%d\")\n",
    "            #Convierto ese tipo de dato fecha en un entero, el dia del año de esa fecha\n",
    "            #Ej. 20210202 es el 2 de febrero y es el dia 33 del año\n",
    "            fechas.append(int(dt.strftime(\"%j\")))\n",
    "            ndvi = df2.iloc[i].ndvi\n",
    "            valores.append(ndvi)\n",
    "            #Solo añado si el valor está por encima de la variable \"borrarDebajo\"\n",
    "            if ndvi >= borrarDebajo:\n",
    "                valores2.append(ndvi)\n",
    "                fechas2.append(int(dt.strftime(\"%j\")))\n",
    "\n",
    "        #Borramos de 'valores2' y 'fechas2' los datos cuyos ndvi sean menores que el dato anterior y al siguiente (valores valle)\n",
    "        #Ejemplo: si tenemos los valores [3,1,2,4], borramos los valores 1 y 2\n",
    "        #Si tenemos los valores [3,1,4], borramos el valor 1\n",
    "        #Borramos los valores valle\n",
    "        for i in range(len(valores2)-1):\n",
    "            if i > 0 and i < len(valores2)-1:\n",
    "                #Si hay 2 valores juntos menores que el anterior y el siguiente, se borran ambos\n",
    "                if i < (len(valores2) - 2) and valores2[i-1] > valores2[i] and valores2[i-1] > valores2[i+1] and valores2[i+2] > valores2[i] and valores2[i+2] > valores2[i+1]:\n",
    "                    del valores2[i]\n",
    "                    del fechas2[i]\n",
    "                    del valores2[i]\n",
    "                    del fechas2[i]\n",
    "                #En el caso de que solo haya un minimo entre 2 puntos\n",
    "                elif valores2[i-1] > valores2[i] and valores2[i+1] > valores2[i]:\n",
    "                    del valores2[i]\n",
    "                    del fechas2[i]        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #Variables:\n",
    "        saltoFechas = 10\n",
    "        saltoFechas2 = 20\n",
    "        saltoFechas3 = 30\n",
    "        añadirPorDebajo = 0.4 #antes se llamaba maximoMinimo\n",
    "        añadirPorEncima = 0.2\n",
    "\n",
    "        #Añado informacion al principio y final de año si no habia\n",
    "        if fechas2[0] > 0:\n",
    "            fechas2.insert(0, 0)\n",
    "            valores2.insert(0, valores2[0])\n",
    "        if fechas2[len(fechas2) -1] < 365:\n",
    "            fechas2.insert(len(fechas2), 365)\n",
    "            valores2.insert(len(valores2), valores2[len(valores2)-1])\n",
    "\n",
    "\n",
    "        #Si hay saltos muy grandes sin informacion se trata:\n",
    "        i = 0\n",
    "        while i < len(fechas2) - 1: \n",
    "            encontrado = False\n",
    "            #Si el salto es muy grande\n",
    "            if (fechas2[i+1]-fechas2[i]) >= saltoFechas3 and i+1 != (len(fechas2) -1) and i != 0:\n",
    "                #buscar maximos locales entre los dos puntos y\n",
    "                aux1 = 0\n",
    "                aux2 = 0\n",
    "                for j in range(len(fechas) - 1):\n",
    "                    if fechas[j] <= fechas2[i] and fechas[j+1] >= fechas2[i]:\n",
    "                        aux1 = j\n",
    "                    elif fechas[j] <= fechas2[i]  and fechas[j+1] >= fechas2[i]   :\n",
    "                        aux2 = j\n",
    "                        break\n",
    "                j = aux1 + 1\n",
    "                auxSum = 0\n",
    "                while (j < aux2):\n",
    "                    if valores[j] > valores[j-1] and valores[j] > valores[j+1]:\n",
    "                        # y volverlos a añadir segun su valor\n",
    "                        if (valores2[i] <= 0.6 and valores2[i+1] <=0.6 and valores[j] <= añadirPorDebajo and valores[j] >= añadirPorEncima):\n",
    "                            fechas2.insert(i+1+ auxSum, fechas[j])\n",
    "                            valores2.insert(i+1+ auxSum, valores[j])\n",
    "                            auxSum = auxSum + 1\n",
    "                            encontrado = True\n",
    "                    j = j + 1\n",
    "\n",
    "\n",
    "\n",
    "            if encontrado == False:    \n",
    "                #Si el salto es intermedio\n",
    "                if (fechas2[i+1]-fechas2[i]) >= saltoFechas2:\n",
    "                    if valores2[i+1] > valores2[i]: #va hacia arriba\n",
    "                        fechas2.insert(i+1, fechas2[i] + ((fechas2[i+1] - fechas2[i]) / 3)*2)\n",
    "                        valores2.insert(i+1, valores2[i] + ((valores2[i+1] - valores2[i]) / 3))\n",
    "                    else: #va hacia abajo\n",
    "                        fechas2.insert(i+1, fechas2[i] + ((fechas2[i+1] - fechas2[i]) / 3))\n",
    "                        valores2.insert(i+1,  valores2[i+1] + ((valores2[i] - valores2[i+1]) / 3))\n",
    "                #Si el salto es pequeño\n",
    "                elif (fechas2[i+1]-fechas2[i]) >= saltoFechas:\n",
    "                    fechas2.insert(i+1, (fechas2[i+1]+fechas2[i])/2)\n",
    "                    valores2.insert(i+1, (valores2[i+1]+valores2[i])/2)\n",
    "            i = i+1\n",
    "\n",
    "\n",
    "        #Plot    \n",
    "        from scipy.interpolate import make_interp_spline\n",
    "        from scipy.interpolate import interp1d\n",
    "\n",
    "        #Esto crea una linea de 365 puntos que pasa por todos los puntos que teniamos\n",
    "        X_Y_Spline = make_interp_spline(fechas2,valores2)        \n",
    "        X = np.linspace(0, 365, 365)\n",
    "        Y = X_Y_Spline(X)\n",
    "\n",
    "        dt = datetime.datetime.strptime(fecha, \"%Y%m%d\")\n",
    "        aux = int(dt.strftime(\"%j\"))\n",
    "\n",
    "        if (show):\n",
    "            plt.figure(figsize=(17,5))\n",
    "            plt.title('parcela: '+ parcela)\n",
    "            plt.plot(fechas, valores,'r-')\n",
    "\n",
    "            plt.xticks(np.arange(0, 365,10))\n",
    "\n",
    "            plt.plot(X, Y, 'b-')\n",
    "            plt.scatter(fechas, valores, c=valores, cmap='Set2')\n",
    "\n",
    "            #Dibujar las lineas verticales asociadas a las fechas de recepcion\n",
    "            #for recepcion in recepciones:\n",
    "            #    if recepcion[0] == parcela:\n",
    "            #        for aux in recepcion[1]:\n",
    "            #            dt = datetime.datetime.strptime(aux, \"%Y%m%d\")\n",
    "            #            aux2 = int(dt.strftime(\"%j\"))\n",
    "            #            plt.axvline(x=(aux2))  \n",
    "            #        break\n",
    "\n",
    "            #dt = datetime.datetime.strptime(fecha, \"%Y%m%d\")\n",
    "            #aux = int(dt.strftime(\"%j\"))\n",
    "            plt.axvline(x=(aux), linewidth=2, color='black') \n",
    "            print('dia de recepcion: ',aux)\n",
    "            interseccion = intersection(tp,fp)\n",
    "            print('true positives: ', interseccion)\n",
    "\n",
    "\n",
    "            [plt.axvline(_x, linewidth=1, color='orange') for _x in interseccion]\n",
    "\n",
    "            if len(interseccion) > 0:\n",
    "                for i in interseccion:\n",
    "                    tp.remove(i)\n",
    "                    fp.remove(i)\n",
    "            [plt.axvline(_x, linewidth=1, color='g') for _x in tp]\n",
    "            [plt.axvline(_x, linewidth=1, color='r') for _x in fp]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            plt.xlabel(\"X\")\n",
    "            plt.ylabel(\"Y\")\n",
    "            plt.ylim([0, 1])\n",
    "            plt.legend([\"puntos originales\",\"puntos modificados\",\"recepcion\"])\n",
    "            plt.show()\n",
    "\n",
    "        return [Y, aux]\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    dfFechas = pd.read_csv('PARCELAS-MAIZ-2021-2022-CON-FECHAS.csv')\n",
    "\n",
    "    freq = dfFechas['PAC'].value_counts()\n",
    "    items = freq[freq==1].index\n",
    "    only_1_reception = dfFechas[dfFechas['PAC'].isin(items)]\n",
    "\n",
    "    newPac = only_1_reception[\"PAC\"].str.replace(\":\", \"_\")\n",
    "    newDate = only_1_reception[\"Fecha de carga\"].str.replace(\"-\", \"\")\n",
    "\n",
    "    only_1_reception[\"PAC\"] = newPac\n",
    "    only_1_reception[\"Fecha de carga\"] = newDate\n",
    "    only_1_reception['Fecha de carga'] = only_1_reception['Fecha de carga'].apply(str)\n",
    "\n",
    "    df = pd.read_csv('TODOSLOSRECINTOS.csv')\n",
    "\n",
    "    #Ordeno por fecha y parcela\n",
    "    sorted_df = df.sort_values(by=[\"fecha\",\"parcela\"], ascending=True)\n",
    "    sorted_df = sorted_df.drop(columns=['Unnamed: 0'])\n",
    "    parcelasQueTengo = sorted_df[\"parcela\"].unique()\n",
    "    parcelasConUnaRecepcion = only_1_reception[\"PAC\"].unique()\n",
    "\n",
    "    df_ndvi_of_only_1_reception = sorted_df[sorted_df.parcela.isin(only_1_reception[\"PAC\"].unique())]\n",
    "\n",
    "    dias1 = 7\n",
    "    dias2 = 180\n",
    "\n",
    "\n",
    "    i = 0\n",
    "    #parcelas = df_ndvi_of_only_1_reception['parcela'].unique()\n",
    "    dataframeAux = dataframeTest\n",
    "    parcelas = dataframeAux['parcela'].unique()\n",
    "    for parcela in parcelas:\n",
    "        df2 = df_ndvi_of_only_1_reception.loc[df_ndvi_of_only_1_reception['parcela'] == parcela]\n",
    "        df2 = df2.drop_duplicates()\n",
    "        if (not df2.empty):\n",
    "            fecha_df = only_1_reception.loc[only_1_reception[\"PAC\"] == parcela] \n",
    "            fecha = fecha_df.iloc[0][\"Fecha de carga\"]\n",
    "\n",
    "            datos = dataframeAux.loc[dataframeAux['parcela'] == parcela]\n",
    "            dias = dataframeDias.loc[dataframeDias['parcela'] == parcela]['dia']\n",
    "            #print('------------------')\n",
    "            #print(parcela, 'dias:')\n",
    "            tp = list(dias)\n",
    "            #print(dias)\n",
    "            Xtest = np.asarray(dataframeAux.loc[dataframeAux['parcela'] == parcela].drop(columns=['parcela','dia','recogido'])).astype(np.float32)\n",
    "            ytest = np.asarray(dataframeAux.loc[dataframeAux['parcela'] == parcela][[\"recogido\"]]).astype(np.float32)\n",
    "            ypred = model.predict(Xtest, verbose=0)\n",
    "            fp = list()\n",
    "            #print(len(ypred))\n",
    "            for i in range(len(ypred)):\n",
    "                if ypred[i] >= 0.6:\n",
    "                    fp.append(datos.iloc[i]['dia'])\n",
    "\n",
    "            #print(tp, fp)\n",
    "            if len(intersection(tp, fp)) > 0:\n",
    "                X, dia_recepcion = algoritmo(df2, fecha, True, tp, fp)\n",
    "\n",
    "\n",
    "            i = i + 1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3efbf5a",
   "metadata": {},
   "source": [
    "Voy a volver a calcular todos los datos pero sin borrar los datos que no haya podido obtener:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f79bbf",
   "metadata": {},
   "source": [
    "Cargo 'datosEntrenables20221128' que es donde tengo la informacion de todas las parcelas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b49f9018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('datosEntrenables20221128.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df['tmed'] = np.full(len(df), 'not inialized')\n",
    "df['prec'] = np.full(len(df), 'not inialized')\n",
    "df['precSum3'] = np.full(len(df), 'not inialized')\n",
    "df['estacion'] = np.full(len(df), 'not inialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6a67bb8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/8\n",
      "50_209_0_0_60_12_7\n",
      "1/7\n",
      "50_209_0_0_60_12_8\n",
      "1/6\n",
      "50_209_0_0_63_2_34\n",
      "1/5\n",
      "50_209_0_0_64_38_113\n",
      "1/4\n",
      "50_209_0_0_64_38_115\n",
      "1/3\n",
      "50_209_0_0_64_38_195\n",
      "1/2\n",
      "50_209_0_0_64_38_202\n",
      "1/1\n",
      "50_209_0_0_93_26_1\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import csv\n",
    "import warnings\n",
    "API_ENDPOINT3 = \"http://maps.agroslab.com/AgroslabHttpServlet/AgroslabHttpServlet\"\n",
    "HEADERS = {'Content-Type': 'application/json'}\n",
    "AUTH=('agroslabsecure','5rp6aLvVb6HU')\n",
    "parcelasSinInformacion = list()\n",
    "parcelasAObservar = df.loc[df['estacion'] == 'not inialized']\n",
    "parcelasAObservar = parcelasAObservar['parcela'].unique()\n",
    "progreso = 1\n",
    "total= len(parcelasAObservar)\n",
    "\n",
    "for parcela in parcelasAObservar:\n",
    "    print(str(progreso) + '/' + str(total))\n",
    "    print(parcela)\n",
    "    datosParcela = df.loc[df['parcela'] == parcela]\n",
    "    diaMin = str(datosParcela['dia'].iloc[0]-3) + \"-01-2021\"\n",
    "    diaMax = str(datosParcela['dia'].iloc[len(datosParcela)-1]-1) + \"-01-2021\"\n",
    "    \n",
    "    recinto = parcela.replace(\"_\",\"-\")\n",
    "    PARAMS = {\"operation\" : \"aemetestacionesdwithin\",\n",
    "        \"id\": recinto,\n",
    "        \"distanceinkilometers\": 100}\n",
    "    \n",
    "    r = requests.post(url = API_ENDPOINT3, headers=HEADERS, json= PARAMS, auth=AUTH, verify=False)\n",
    "    \n",
    "    cogerEstacion = 0\n",
    "    hayInformacionEnParcela = True\n",
    "    while True:\n",
    "        #print(cogerEstacion)\n",
    "        if cogerEstacion >= len(r.json()['aemet_estaciones']):\n",
    "            parcelasSinInformacion.append(recinto.replace('-','_'))\n",
    "            hayInformacionEnParcela = False\n",
    "            break\n",
    "        else:\n",
    "            estacion = r.json()['aemet_estaciones'][cogerEstacion]['id']\n",
    "\n",
    "            PARAMS2 = {\"operation\" : \"aemetclimatologiadiaria\",\n",
    "              \"initdate\":diaMin,\n",
    "              \"enddate\":diaMax,\n",
    "              \"idema\" : estacion}\n",
    "\n",
    "            r2 = requests.post(url = API_ENDPOINT3, headers=HEADERS, json= PARAMS2, auth=AUTH, verify=False)\n",
    "            if \"error\" in r2.json():\n",
    "                cogerEstacion = cogerEstacion + 1\n",
    "            else:\n",
    "                break\n",
    "    \n",
    "    if hayInformacionEnParcela:\n",
    "        \n",
    "        #print(recinto)\n",
    "        #print(diaMin)\n",
    "        #print(diaMax)\n",
    "        #print(r.json())\n",
    "        #print('-------------------------------------------------------------------------------------------')\n",
    "        listaTmed = list()\n",
    "        listaPrec = list()\n",
    "        for info in r2.json():\n",
    "            if \"tmed\" in info:\n",
    "                listaTmed.append(info['tmed'])\n",
    "            else:\n",
    "                print(\"tmed\")\n",
    "                print(estacion)\n",
    "                \n",
    "            if \"prec\" in info:\n",
    "                if info['prec'] == 'Ip':\n",
    "                    listaPrec.append('0,0')\n",
    "                else: \n",
    "                    listaPrec.append(info['prec'])\n",
    "            else:\n",
    "                print(\"prec\")\n",
    "                print(estacion)\n",
    "                \n",
    "\n",
    "        indices = datosParcela.index\n",
    "        pos = 0\n",
    "        if len(listaTmed) != 22 or len(listaPrec) != 22:\n",
    "            continue\n",
    "        progreso += 1\n",
    "        for i in indices:\n",
    "            df.at[i,'tmed'] = float(listaTmed[pos+ 2].replace(',','.'))\n",
    "            if (listaPrec[pos+2] == 'Ip'):\n",
    "                df.at[i,'prec'] = float(0)\n",
    "            else:\n",
    "                df.at[i,'prec'] = float(listaPrec[pos+2].replace(',','.'))\n",
    "            \n",
    "            df.at[i,'precSum3'] = float(listaPrec[pos].replace(',','.')) + float(listaPrec[pos+1].replace(',','.')) + float(listaPrec[pos+2].replace(',','.'))\n",
    "            df.at[i,'estacion'] = estacion\n",
    "            pos = pos + 1\n",
    "    else:\n",
    "        total -= 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5817df8d",
   "metadata": {},
   "source": [
    "Ejecutando varias veces el bloque anterior eventualmente tendremos informacion para todas las parcelas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf38982f",
   "metadata": {},
   "source": [
    "Ahora hay que entrenar con los datos que no tienen 'not initialized' en [estacion]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9350dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcela</th>\n",
       "      <th>dia</th>\n",
       "      <th>pendiente dia -15</th>\n",
       "      <th>pendiente dia -10</th>\n",
       "      <th>pendiente dia -5</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>recogido</th>\n",
       "      <th>tmed</th>\n",
       "      <th>prec</th>\n",
       "      <th>precSum3</th>\n",
       "      <th>estacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>292</td>\n",
       "      <td>0.013078</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>0.456587</td>\n",
       "      <td>0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>293</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.467762</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>294</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>0.478748</td>\n",
       "      <td>0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>295</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>-0.009899</td>\n",
       "      <td>0.488632</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>296</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>-0.003832</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.496736</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>289</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.414865</td>\n",
       "      <td>0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.409131</td>\n",
       "      <td>0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>291</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.402966</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>292</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.396435</td>\n",
       "      <td>0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>293</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.389605</td>\n",
       "      <td>0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8160 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   parcela  dia  pendiente dia -15  pendiente dia -10  \\\n",
       "0     22_27_0_1_503_5017_1  292           0.013078           0.008582   \n",
       "1     22_27_0_1_503_5017_1  293           0.011039           0.005081   \n",
       "2     22_27_0_1_503_5017_1  294           0.008906           0.001723   \n",
       "3     22_27_0_1_503_5017_1  295           0.006757          -0.001304   \n",
       "4     22_27_0_1_503_5017_1  296           0.004652          -0.003832   \n",
       "...                    ...  ...                ...                ...   \n",
       "8155    50_224_0_2_18_50_1  289           0.005049           0.004059   \n",
       "8156    50_224_0_2_18_50_1  290           0.005029           0.004006   \n",
       "8157    50_224_0_2_18_50_1  291           0.004980           0.004131   \n",
       "8158    50_224_0_2_18_50_1  292           0.004917           0.004413   \n",
       "8159    50_224_0_2_18_50_1  293           0.004868           0.004802   \n",
       "\n",
       "      pendiente dia -5      ndvi  recogido  tmed prec precSum3 estacion  \n",
       "0            -0.002236  0.456587         0  17.4  0.0      0.0     9898  \n",
       "1            -0.006042  0.467762         0  18.0  0.0      0.0     9898  \n",
       "2            -0.008617  0.478748         0  17.6  0.0      0.0     9898  \n",
       "3            -0.009899  0.488632         0  15.5  0.0      0.0     9898  \n",
       "4            -0.010032  0.496736         0  13.7  0.0      0.0     9898  \n",
       "...                ...       ...       ...   ...  ...      ...      ...  \n",
       "8155          0.004025  0.414865         0  16.8  0.0      0.0    9434P  \n",
       "8156          0.004614  0.409131         0  16.4  0.0      0.0    9434P  \n",
       "8157          0.005174  0.402966         0  17.8  0.2      0.2    9434P  \n",
       "8158          0.005670  0.396435         0  18.8  0.0      0.2    9434P  \n",
       "8159          0.006100  0.389605         0  18.8  0.0      0.2    9434P  \n",
       "\n",
       "[8160 rows x 11 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "afe42419",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('datosEntrenables20230131-full.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a8229e",
   "metadata": {},
   "source": [
    "Ahora volvere a probar los modelos pero con mas datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0f97ba6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcelasAQuitar = df.loc[df['estacion'] == 'not inialized']['parcela'].unique()\n",
    "df = df[~df['parcela'].isin(parcelasAQuitar)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "010e5c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcela</th>\n",
       "      <th>dia</th>\n",
       "      <th>pendiente dia -15</th>\n",
       "      <th>pendiente dia -10</th>\n",
       "      <th>pendiente dia -5</th>\n",
       "      <th>ndvi</th>\n",
       "      <th>recogido</th>\n",
       "      <th>tmed</th>\n",
       "      <th>prec</th>\n",
       "      <th>precSum3</th>\n",
       "      <th>estacion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>292</td>\n",
       "      <td>0.013078</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>-0.002236</td>\n",
       "      <td>0.456587</td>\n",
       "      <td>0</td>\n",
       "      <td>17.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>293</td>\n",
       "      <td>0.011039</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>-0.006042</td>\n",
       "      <td>0.467762</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>294</td>\n",
       "      <td>0.008906</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>-0.008617</td>\n",
       "      <td>0.478748</td>\n",
       "      <td>0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>295</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>-0.001304</td>\n",
       "      <td>-0.009899</td>\n",
       "      <td>0.488632</td>\n",
       "      <td>0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22_27_0_1_503_5017_1</td>\n",
       "      <td>296</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>-0.003832</td>\n",
       "      <td>-0.010032</td>\n",
       "      <td>0.496736</td>\n",
       "      <td>0</td>\n",
       "      <td>13.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8155</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>289</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.414865</td>\n",
       "      <td>0</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8156</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>290</td>\n",
       "      <td>0.005029</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.409131</td>\n",
       "      <td>0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8157</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>291</td>\n",
       "      <td>0.004980</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.402966</td>\n",
       "      <td>0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>292</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.004413</td>\n",
       "      <td>0.005670</td>\n",
       "      <td>0.396435</td>\n",
       "      <td>0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8159</th>\n",
       "      <td>50_224_0_2_18_50_1</td>\n",
       "      <td>293</td>\n",
       "      <td>0.004868</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.389605</td>\n",
       "      <td>0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>9434P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   parcela  dia  pendiente dia -15  pendiente dia -10  \\\n",
       "0     22_27_0_1_503_5017_1  292           0.013078           0.008582   \n",
       "1     22_27_0_1_503_5017_1  293           0.011039           0.005081   \n",
       "2     22_27_0_1_503_5017_1  294           0.008906           0.001723   \n",
       "3     22_27_0_1_503_5017_1  295           0.006757          -0.001304   \n",
       "4     22_27_0_1_503_5017_1  296           0.004652          -0.003832   \n",
       "...                    ...  ...                ...                ...   \n",
       "8155    50_224_0_2_18_50_1  289           0.005049           0.004059   \n",
       "8156    50_224_0_2_18_50_1  290           0.005029           0.004006   \n",
       "8157    50_224_0_2_18_50_1  291           0.004980           0.004131   \n",
       "8158    50_224_0_2_18_50_1  292           0.004917           0.004413   \n",
       "8159    50_224_0_2_18_50_1  293           0.004868           0.004802   \n",
       "\n",
       "      pendiente dia -5      ndvi  recogido  tmed prec precSum3 estacion  \n",
       "0            -0.002236  0.456587         0  17.4  0.0      0.0     9898  \n",
       "1            -0.006042  0.467762         0  18.0  0.0      0.0     9898  \n",
       "2            -0.008617  0.478748         0  17.6  0.0      0.0     9898  \n",
       "3            -0.009899  0.488632         0  15.5  0.0      0.0     9898  \n",
       "4            -0.010032  0.496736         0  13.7  0.0      0.0     9898  \n",
       "...                ...       ...       ...   ...  ...      ...      ...  \n",
       "8155          0.004025  0.414865         0  16.8  0.0      0.0    9434P  \n",
       "8156          0.004614  0.409131         0  16.4  0.0      0.0    9434P  \n",
       "8157          0.005174  0.402966         0  17.8  0.2      0.2    9434P  \n",
       "8158          0.005670  0.396435         0  18.8  0.0      0.2    9434P  \n",
       "8159          0.006100  0.389605         0  18.8  0.0      0.2    9434P  \n",
       "\n",
       "[8000 rows x 11 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b4f2b78a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['50_209_0_0_60_12_7', '50_209_0_0_60_12_8', '50_209_0_0_63_2_34',\n",
       "       '50_209_0_0_64_38_113', '50_209_0_0_64_38_115',\n",
       "       '50_209_0_0_64_38_195', '50_209_0_0_64_38_202',\n",
       "       '50_209_0_0_93_26_1'], dtype=object)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['prec'] == 'not inialized']['parcela'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a2e46571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['50_209_0_0_60_12_7', '50_209_0_0_60_12_8', '50_209_0_0_63_2_34',\n",
       "       '50_209_0_0_64_38_113', '50_209_0_0_64_38_115',\n",
       "       '50_209_0_0_64_38_195', '50_209_0_0_64_38_202',\n",
       "       '50_209_0_0_93_26_1'], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['prec'] == 'not inialized']['parcela'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5031b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
